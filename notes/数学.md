#### 似然和极大似然

概率：在已知模型参数的情况下预测结果P（x|θ）

似然：基于结果反推事物本身性质，在已知结果的情况下推断模型参数L（θ|x）

θ：环境中参数

x：事件发生的结果

![{43BCFF30-9F4B-4ed7-8D78-F986C4BE6C71}](D:\Typora\notes\数学.assets\{43BCFF30-9F4B-4ed7-8D78-F986C4BE6C71}.png)

最大似然估计指的是θ等于多少时前面的预测最有可能发生

![{F0889112-828B-4b87-AC80-DEEE8B76A792}](D:\Typora\notes\数学.assets\{F0889112-828B-4b87-AC80-DEEE8B76A792}.png)

### 点乘

对于三维向量 A = (a₁, a₂, a₃) 和 B = (b₁, b₂, b₃)，点乘的计算方式如下：

A · B = a₁ * b₁ + a₂ * b₂ + a₃ * b₃

点乘的结果是一个实数，它表示了两个向量之间的相似性或关联程度。如果两个向量的点乘结果为零，那么它们是垂直的，也就是说它们之间的夹角为90度。

### Skip-gram 模型和 Continuous Bag of Words (CBOW) 模型

ux (Input Vector): 输入向量，通常用于将一个词汇映射到词汇空间中的向量。它表示一个词汇的上下文或周围词汇信息。

vx (Output Vector): 输出向量，通常用于从词汇空间中的向量中预测其他词汇。它表示一个词汇用于预测其他词汇的能力。

![img](D:\Typora\notes\数学.assets\wps1.jpg)

在给定的公式中，目标函数 J(𝜃) 和似然函数 L(𝜃) 之间的关系如下：

1. **似然函数 L(𝜃)**:
   - 似然函数 L(𝜃) 表示在给定参数 𝜃 下，文本数据出现的似然性。它度量了模型对观测数据的拟合程度。在这个上下文中，似然函数通常是关于模型参数 𝜃 的函数，用于描述模型生成或解释观测数据的能力。
2. **目标函数 J(𝜃)**:
   - 目标函数 J(𝜃) 是似然函数 L(𝜃) 的负对数形式（或者说是似然函数的对数似然的相反数），具体表示为 J(𝜃) = -log(L(𝜃))。这个形式的目标函数通常在机器学习和统计中用于优化目的。
   - 目标函数 J(𝜃) 的目标通常是最小化，因为最小化 -log(L(𝜃)) 等效于最大化似然函数 L(𝜃)。也就是说，通过最小化目标函数 J(𝜃)，我们试图找到使观测数据在给定模型下的概率最大的参数 𝜃。

所以，这个公式中的目标函数 J(𝜃) 是用于优化似然函数 L(𝜃) 的形式，目标是通过调整模型参数 𝜃 来最大化似然函数，从而提高模型对观测数据的拟合程度。在很多机器学习问题中，优化目标函数 J(𝜃) 通常是通过梯度下降等优化算法来完成的。

### 梯度函数

1. **变化率和偏导数：** 偏导数衡量了函数在某一方向上的变化率。具体来说，偏导数告诉你，当你在一个特定方向上稍微改变自变量时，函数值会以多快的速度变化。正如你所说，函数的偏导数值越大，沿着那个方向移动，函数值的增加（上升）或减少（下降）越快。
2. **梯度的方向：** 在多元函数中，梯度是一个向量，包含了所有偏导数的值，它指示了函数在哪个方向上变化最快。梯度的方向是函数上升最快的方向，而梯度的负方向是函数下降最快的方向。
3. **梯度下降和最优化：** 在优化问题中，我们经常需要找到一个函数的最小值或最大值。梯度下降是一种常用的方法，它基于以下观点：如果你从一个点出发，沿着梯度的反方向移动，那么你将朝着函数值减小的方向前进，因此可以找到局部最小值。这是因为梯度的反方向指示了函数下降最快的方向。